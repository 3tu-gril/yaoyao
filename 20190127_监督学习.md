# 1.2 监督学习
监督学习的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测。也就是从训练数据集合中学习模型，对测试数据进行预测。
## 1.2.1 基本概念
1 输入空间，特征空间与输出空间
* 输入空间：输入所有可能取值的集合。
* 输出空间：输出所有可能取值的集合。
* 输入空间与输出空间可以是有限个元素的集合，也可以是整个欧式空间，输入空间与输出空间可以是同一个空间，也可以是不同空间，但通常输出空间远远小于输入空间。
* 每个具体的输入是一个实例（instance），通常由特征向量表示，所有特征向量存在的空间成为特征空间。
* 输入x的特征向量记作:
$x=(x^1.x^2,x^i,x^n)$
其中$x^i$表示x中的第i个特征
* 训练集通常表示为：
$T=${($x_1$,$y_1$),($x_2$,$y_2$)...($x_n$,$y_n$)}
* 测试数据也由相应的输入与输出对组成，输入与输出又称为样本或样本点。
* 回归问题：输入变量与输出变量均为连续变量的预测问题。
* 分类问题：输出变量为有限个离散变量的预测问题
* 标注问题：输入变量与输出变量均为变量序列的预测问题。
2 联合概率分布
监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y),P(X,Y)表示分布函数 ，或分布密度函数。
3 假设空间
监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。学习的目的就在于找到最好的这样的模型。
* 监督学习的模型可以是概率模型也可以是非概率模型，由条件概率分布P(Y|X)或决策函数Y=f(X)表示。
## 1.2.2 问题的形式化
# 1.3 统计学习三要素
统计学习的方法=模型+策略+算法
##1.3.1 模型
* 模型：是所要学习的条件概率分布或决策函数。
* 模型的假设空间：包含所有可能的条件概率分布或决策函数。
##1.3.2 策略
建立的模型的假设空间后，统计学习要考虑按照什么样的准则学习或选择最优的模型。
* 统计学习的目标在于从假设空间中选取最优模型。
1 损失函数和风险函数
输出的预测值$f(X)$与真实值$Y$可能一直也可能不一致，所以用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。
* 损失函数是f(X)和Y的非负实值函数，记作$L(Y,f(X))$
* 统计学习中常用的几种损失函数（见手写笔记)
* 0-1 损失函数
* 平方损失函数
* 绝对损失函数
* 对数损失函数
损失函数值越小，模型越好，怎么样评估损失函数呢？就有了风险函数或称为期望损失。
2 经验风险最小化和结构风险最小化
## 1.3.3 算法
算法是指学习模型的具体算法，统计学习基于基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。
#1.4 模型评估与模型选择
## 1.4.1 训练误差与测试误差
当损失函数给定时，基于损失函数的模型的训练误差和模型的测试误差，就自然成为学习方法评估的标准。
## 1.4.2 过拟合与模型选择
当假设空间含有不同复杂度（例如，不同的参数个数）的模型时，就要面临模型选择的问题。 
* 如果一味的追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高，这种现象称为过拟合（over-fitting)           
* 过拟合是指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测的很好，但对未知数据预测的很差的现象。
* 模型选择旨在避免过拟合并提高模型的预测能力。
* 过拟合现象本质就是训练误差减小，测试误差增大。
